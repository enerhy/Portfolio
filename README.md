# Portfolio
This repository contains a subset of the Machine Learning and Computer Vision projects I've been working on. 
The content will be continuously updated since I am improving the existing projects and adding new ones.
The aim of this repository is to show my knowledge to people interested.

## Visual:
* **Rooftops surface decomposition:** The task is to automatically segment rooftops edges in orthophotos and so decompose them into their respective surface parts. An supervised Deep Learning approach is used with VGG16 ancoder, with ImageNet pretrained weights and Transposed Convolutions in the decoder. Custom Loss combining Dice Loss and Crossentropy in 3:1 proportion and class weighting is used. I use Adam optimizer with a custom Learning Rate Scheduler. In this notebook I use low-level Tensorflow code with custom Losses and Metrics, training with tf.GradientTape(). Furthermore I use th.data structures with performance optimization techniques such as data caching, data prefetching, data batching, parallelizing and TensorFlow graph operations.
* **Buildings'footprints detection for cadaster verification:** Specification and preprocessing of 16bits multispectral satellite images of Sofia, including pan-sharpening, channels extraction and blending, tiling, and resizing while keeping geo-spatial accuracy. Use of a pretrained segmentation model with PyTorch 
and Solaris. Model’s transferability assessment on official cadastral data.
* **Face Recognition:** FaceNet, Multi-Task Cascaded Convolutional Neural Network and a linear SVC with Kearas
* **Neuro Style Transfer:** Generating Images based VGG19 implementing Style and Content Loss from intermediate layers and training using  Tensorflow 2.x Graph mode
* **YOLOv2_Object_Detection:** Application of YOLOv2 Object Detection algorithm in Tensorflow 2.x with weights pretrained on the COCO-Dataset. The algorithm performs pretty well in detecting and recognizing the 80 classes. It could be extended to work on custom classes and to work on video. The work uses the work of Allan Zelender and Andrew Ng (Coursera course), however extends them by applying Tensorflow 2.x with some minor additions. 
* **Recognizing Blood Cells disorders:** An exercise of implementing several different CNN type of blocks/layers including: ResNet blocks, Inception blocks, One-to-One convolutions. Additionally, partial reuse of pretrained weights on ResNet50 and Inception with self-training of part of the network with early stopping.
* **Defets Detection and Localization:** Solution for the or the [Severstal: Steel Defect Detection Competition](https://www.kaggle.com/c/severstal-steel-defect-detection). The goal is to precisly localize multiple different type of deffects on an image from produced sheet steel. A U-Net Segmentation with a ResNet34 Backbone and pretrained weights on Imagenet have been used.  
* **Image Segmentation with U-Net:** Implementation of U-Net with MobileNetV2 as encoder and simple Upsampling as decoder. Use of tf.dataset and techniqes for speed improvement such as to-Graph conversion, cashing, prefetching and parallel processing. Replication of the Tensorflow official tutorial with extensive comments.
* **Cifar10:** Image Classification with 10 classes. Use of basic EDA, Data Augmentation and custom CNN for prediction.
## Tabular:
* **House SalePrice Prediction:** Regression problem. EDA and use of a number of Feature Engineering and Feature Selection techniques. Finally use of ANN and XGBoost for prediction
* **Santander Customer Satisfaction:** Classification problem with highly imbalanced data. EDA and use of a number of Feature Engineering and Feature Selection techniques. Two of the most modern gradient boosted decision tree models: XGboost and LightGBM are applied to make predictions with weighting the loss due to the unbalanced data.
* **Categorical Encoding:** Use of a number of categorical encoding techniques including: Ordinal label encoding, Binary encoding, Hash tricks, Encoding based on mean target value, Encoding based on alphabetical order of strings, Encoding of cyclical data
* **Ensemble Titanic:** Use of 2-stages Ensemble Learning on the Titanic Dataset. In the first stage I build a base classification composed of several different classification algorithms with Kflodnd and use a democracy voting for comparison with the final result. Finally, I use an ANN on the result from the first stage along with scalled preprocessed features for the final classification.
* **Mercedes-Benz Greener Manufacturing:** Regression problem over an anonymized dataset representing different permutations of Mercedes-Benz car features. Goals is to predict time for a car to pass testing. EDA and use of a number of Feature Engineering and Feature Selection techniques. Finally use of LightGBM with log-scalled dependent variable for an R2 result close to best scode
* **Porto Seguro’s Safe Driver Prediction:** The aim is to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. The target data is highly imbalanced and the features are anonymized. For the evaluation a Gini Coefficient is used. In this Kernel I am experimenting with different techniqes to tackel problem with the imbalanced target such as weighting errors and stratified model stacking. Also I try different over- and under-sampling methods and combination of both. Work in progress
## Other Computer Vision:
* **Automated test scorring system with OpenCV:** This is a simple system for automated scoring of multiple choice tests. Input is an image of a submitted test sheet and key of the correct answers. The result is marked and scorred exam paper. Techniques used include perspective transformation, thresholding, blurring, contours extraction, part of image extraction with mask.
* **Image Detection with OpenCV:** In the notebook I perform an image detection of a painting in an image containing several paintings (but extendanle to a database). I use SURF (speeded up robust features) for keypoint description. It implements DoG (Difference of Gaussians) to detect the keypoints. Based on that I use FLANN algorithm (Fast Library for Approximate Nearest Neighbors) to filter the results. Furthermore, the robustness of the detection is assessed using altered images of the original painting and a remake.
* **Image Classification with BoW in OpenCV:** This notebook exxplores the results of a SVM (Suport Vector Machines) classifier using the descriptions of visual keypoints (detected with DoG - Difference of Gaussians) clustered with K-means into BoW (Bag of Words) vocabulary.

